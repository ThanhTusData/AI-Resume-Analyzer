{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7747b229-0ba4-4199-ae1f-7ecda82893f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "AIzaSyDW8yBs5srMHPW2rbkX7OkJQmAPppvef_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9126875-a23f-4741-9f6f-0c6f7bd14a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from google import genai\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9e0c45f-ec36-4feb-a857-5b56f841dc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PyPDF2._reader.PdfReader object at 0x0000026B7B1948F0>\n"
     ]
    }
   ],
   "source": [
    "pdf = \"C:/Users/thanh/Downloads/CV - Data Scientist - Trương Nguyễn Thanh Tú.pdf\"\n",
    "pdf_reader = PdfReader(pdf)\n",
    "print(pdf_reader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b5538ce-c30a-46c6-b827-76d201f093ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Programming: Python (Pandas, NumPy, Scikit-learn,\n",
      "TensorFlow, PySpark), R, SQL\n",
      "Databases & Querying: SQL Server, MySQL,\n",
      "PostgreSQL, ClickHouse, MongoDB, Cassandra\n",
      "Machine Learning: Regression, Classification,\n",
      "Clustering, Recommender Systems (MF, KNN), Online\n",
      "Learning (SGD, Passive-Aggressive), Time Series\n",
      "Forecasting\n",
      "Tools & Platforms: Apache Spark, Airflow, Docker,\n",
      "Kafka, Git, REST API (Postman)\n",
      "Visualization & BI: Power BI (DAX), Grafana, ExcelBusiness Intelligence & KPI Analysis\n",
      "Data Storytelling for Stakeholders\n",
      "Domain Knowledge: E-commerce, Finance, Education\n",
      "Project Planning & Execution\n",
      "Communication with Technical & Non-Technical\n",
      "Teams\n",
      "Business Acumen in Decision-MakingOBJECTIVE · 0982653370 · thanhtu.data.analyst@gmail.com\n",
      " · https://www.linkedin.com/in/truong-nguyen-thanh-tu-a9a406324/\n",
      " · https://github.com/ThanhTusData\n",
      " ·  District 10, Ho Chi Minh City, Viet NamTRUONG NGUYEN THANH TU\n",
      "PROFESSIONAL EXPERIENCESTRENGTHS AND EXPERTISEDATA SCIENTIST\n",
      "Applied Mathematics student with a strong foundation in arithmetic and matrix theory, passionate about harnessing the power of data. Proactively\n",
      "learning and applying data-analysis tools, I aim to deepen my expertise to support both academic and real-world projects. Within two years, I aspire to\n",
      "become a data specialist who drives business value by turning information into strategic insights.\n",
      "Data Cleaning & Preprocessing\n",
      "Feature Engineering & Selection\n",
      "Model Evaluation & Tuning (Cross-validation,\n",
      "Grid Search)\n",
      "Statistical Analysis: Hypothesis Testing, A/B\n",
      "Testing\n",
      "Pattern Recognition & Anomaly Detection\n",
      "Data-Driven Problem Solving\n",
      "Beloved & Beyond   ----   Role: Data Analyst Intern   ----   Probation Period: 02/2025-05/2025\n",
      "MyInsight - MDS Datathon Challenge 2025   ----   Competition Period: 05/2025HONORS & AWARDS\n",
      "Led and supported a team that successfully advanced to the semi-final round, placing in the TOP 20 best-performing teams out of hundreds of\n",
      "participants.Managed and cleansed multi-million-row datasets using Excel, Jupyter Notebook, and Python, then performed analyses and visualizations to reveal\n",
      "key revenue, product, and customer insights.\n",
      "Developed and deployed machine learning models in Python (Jupyter Notebook) for missing-value imputation and delivered analytical reports on sales\n",
      "trends and customer behavior.\n",
      "Architected and maintained Dockerized data pipelines with Kafka, MySQL, ClickHouse, and Python to ingest, process, and store API data for advanced\n",
      "analytics.\n",
      "EDUCATION CERTIFICATIONS\n",
      "University: Ton Duc Thang University (2023 - 2027)\n",
      "Major: Applied MathematicsHacker Rank:\n",
      "SQL (Advanced)\n",
      "Python (Basic)\n",
      "English:\n",
      "English B1 certification\n",
      "Fluent in EnglishPERSONAL PROJECTS\n",
      "Credit Risk & Customer Segmentation  ----   Conducted in: 05/2025\n",
      "Conducted end-to-end analysis on credit risk data: cleaned, normalized, handled missing values, and balanced classes using SMOTE.\n",
      "Evaluated 13 machine learning models, selected the best performer (AUC > 0.85, F1 > 0.8), and segmented customers using t-SNE and Davies–Bouldin\n",
      "to identify high-risk, loyal, and high-potential groups.\n",
      "Developed a Power BI dashboard and real-time REST API to deliver insights for credit and marketing teams, reducing non-performing loans and\n",
      "boosting campaign effectiveness.\n",
      "Service Usage Behavior Analysis Customer Churn Prediction   ----   Conducted in: 05/2025\n",
      "Conducted EDA with Jupyter Notebook and Python, then visualized key churn patterns and customer segments in Power BI dashboard.\n",
      "Built a churn prediction model using XGBoost (F1 ≈ 0.84, AUC ≈ 0.99) and integrated it with a REST API tested in Postman.\n",
      "Identified high-risk groups and proposed retention strategies, successfully flagging over 80% of potential churn cases.\n",
      "Product Recommendation & User Behavior Analysis   ----   Conducted in: 05/2025\n",
      "Utilized Jupyter Notebook and Python to clean, normalize, and impute data; handled outliers; computed key metrics (AOV, purchase frequency, review\n",
      "scores) to extract actionable user behavior insights.\n",
      "Segmented users with KMeans; built a hybrid recommendation system (ALS-based matrix factorization + KNN); visualized findings in an interactive\n",
      "Power BI dashboard.\n",
      "Achieved a 15% increase in recommendation accuracy, along with enhanced coverage and diversity, enabling more effective marketing campaigns and\n",
      "operational decisions.(Check out my project here: https://github.com/ThanhTusData)\n"
     ]
    }
   ],
   "source": [
    "# extract text from each page separately\n",
    "text = \"\"\n",
    "for page in pdf_reader.pages:\n",
    "    text += page.extract_text()\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2fe52d5-933d-4ac8-8591-b2244dec1b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the long text into small chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000,\n",
    "                                               chunk_overlap=200,\n",
    "                                               length_function=len)\n",
    "\n",
    "chunks = text_splitter.split_text(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb3ac3b8-855f-4e45-921e-d7b734a9b584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Programming: Python (Pandas, NumPy, Scikit-learn,\\nTensorFlow, PySpark), R, SQL\\nDatabases & Querying: SQL Server, MySQL,\\nPostgreSQL, ClickHouse, MongoDB, Cassandra\\nMachine Learning: Regression, Classification,\\nClustering, Recommender Systems (MF, KNN), Online\\nLearning (SGD, Passive-Aggressive), Time Series\\nForecasting\\nTools & Platforms: Apache Spark, Airflow, Docker,\\nKafka, Git, REST API (Postman)\\nVisualization & BI: Power BI (DAX), Grafana, ExcelBusiness Intelligence & KPI Analysis\\nData Storytelling for Stakeholders\\nDomain Knowledge: E-commerce, Finance, Education\\nProject Planning & Execution\\nCommunication with Technical & Non-Technical\\nTeams\\nBusiness Acumen in Decision-MakingOBJECTIVE · 0982653370 · thanhtu.data.analyst@gmail.com\\n · https://www.linkedin.com/in/truong-nguyen-thanh-tu-a9a406324/\\n · https://github.com/ThanhTusData\\n ·  District 10, Ho Chi Minh City, Viet NamTRUONG NGUYEN THANH TU\\nPROFESSIONAL EXPERIENCESTRENGTHS AND EXPERTISEDATA SCIENTIST'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcc968d3-f1a8-42bd-896a-19c3e2c51762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'· https://github.com/ThanhTusData\\n ·  District 10, Ho Chi Minh City, Viet NamTRUONG NGUYEN THANH TU\\nPROFESSIONAL EXPERIENCESTRENGTHS AND EXPERTISEDATA SCIENTIST\\nApplied Mathematics student with a strong foundation in arithmetic and matrix theory, passionate about harnessing the power of data. Proactively\\nlearning and applying data-analysis tools, I aim to deepen my expertise to support both academic and real-world projects. Within two years, I aspire to\\nbecome a data specialist who drives business value by turning information into strategic insights.\\nData Cleaning & Preprocessing\\nFeature Engineering & Selection\\nModel Evaluation & Tuning (Cross-validation,\\nGrid Search)\\nStatistical Analysis: Hypothesis Testing, A/B\\nTesting\\nPattern Recognition & Anomaly Detection\\nData-Driven Problem Solving\\nBeloved & Beyond   ----   Role: Data Analyst Intern   ----   Probation Period: 02/2025-05/2025\\nMyInsight - MDS Datathon Challenge 2025   ----   Competition Period: 05/2025HONORS & AWARDS'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea151ac6-c82e-4778-80e7-27d868518ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Google Gemini API Key:  AIzaSyDW8yBs5srMHPW2rbkX7OkJQmAPppvef_U\n"
     ]
    }
   ],
   "source": [
    "# Get Gemini API key\n",
    "gemini_api_key = input('Enter your Google Gemini API Key: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40dc2962-b08f-4e2e-b0e8-445308229f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gemini_analyze_simple(gemini_api_key, resume_text, analyze_prompt):\n",
    "    \"\"\"\n",
    "    Simple analysis using Google Gemini without vector search\n",
    "    \"\"\"\n",
    "    # Create the prompt with full resume context\n",
    "    prompt = f\"\"\"\n",
    "    Resume Content:\n",
    "    {resume_text}\n",
    "    \n",
    "    Analysis Request: {analyze_prompt}\n",
    "    \n",
    "    Please provide a detailed and comprehensive analysis based on the resume content above.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize Gemini client\n",
    "    client = genai.Client(api_key=gemini_api_key)\n",
    "    \n",
    "    # Generate response using Gemini\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\", \n",
    "        contents=prompt\n",
    "    )\n",
    "    \n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a96ea602-8043-413b-8cf3-1c811ba34f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resume_summary():\n",
    "    query = '''Please provide a detailed summarization of this resume including:\n",
    "                - Personal information and contact details\n",
    "                - Educational background\n",
    "                - Work experience and achievements\n",
    "                - Technical skills and competencies\n",
    "                - Key projects and accomplishments\n",
    "                - Overall professional profile\n",
    "                Finally, provide a conclusion about the candidate's profile.\n",
    "                '''\n",
    "    return query\n",
    "\n",
    "def resume_strength():\n",
    "    query = '''Please provide a detailed analysis of the strengths of this resume including:\n",
    "                - Technical skills and expertise\n",
    "                - Professional experience highlights\n",
    "                - Educational qualifications\n",
    "                - Project achievements\n",
    "                - Industry knowledge\n",
    "                - Soft skills demonstrated\n",
    "                Finally, conclude with the main competitive advantages of this candidate.\n",
    "                '''\n",
    "    return query\n",
    "\n",
    "def resume_weakness():\n",
    "    query = '''Please provide a detailed analysis of the weaknesses of this resume and suggestions for improvement:\n",
    "                - Areas that need more detail or clarification\n",
    "                - Missing information or skills\n",
    "                - Formatting or presentation issues\n",
    "                - Experience gaps or concerns\n",
    "                - Skills that could be better highlighted\n",
    "                - Specific recommendations for improvement\n",
    "                Finally, provide actionable steps to make this resume stronger.\n",
    "                '''\n",
    "    return query\n",
    "\n",
    "def job_title_suggestion():\n",
    "    query = '''Based on this resume, what are the most suitable job roles this candidate can apply for on LinkedIn? Please provide:\n",
    "                - Primary job titles that match perfectly\n",
    "                - Secondary job titles that could be a good fit\n",
    "                - Industries and company types to target\n",
    "                - Required skills to highlight in applications\n",
    "                - Career progression opportunities\n",
    "                Finally, rank the top 5 most suitable positions for this candidate.\n",
    "                '''\n",
    "    return query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c74e2f06-ebde-44cc-a43c-aaac1cc12927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESUME SUMMARY ===\n",
      "Here's a detailed summarization and analysis of the provided resume:\n",
      "\n",
      "## Resume Summary and Analysis\n",
      "\n",
      "**1. Personal Information and Contact Details:**\n",
      "*   **Name:** TRUONG NGUYEN THANH TU\n",
      "*   **Contact Number:** 0982653370\n",
      "*   **Email:** thanhtu.data.analyst@gmail.com\n",
      "*   **LinkedIn Profile:** https://www.linkedin.com/in/truong-nguyen-thanh-tu-a9a406324/\n",
      "*   **GitHub Profile:** https://github.com/ThanhTusData\n",
      "*   **Location:** District 10, Ho Chi Minh City, Viet Nam\n",
      "\n",
      "**2. Educational Background:**\n",
      "*   **University:** Ton Duc Thang University\n",
      "*   **Major:** Applied Mathematics\n",
      "*   **Period:** 2023 - 2027 (Indicating current enrollment with an expected graduation in 2027)\n",
      "\n",
      "**3. Work Experience and Achievements:**\n",
      "The resume lists a \"PROFESSIONAL EXPERIENCE\" section with three bullet points describing significant achievements, followed by an \"upcoming\" internship.\n",
      "*   **Demonstrated Achievements (Unspecified Professional Experience Context):**\n",
      "    *   Managed and cleansed multi-million-row datasets using Excel, Jupyter Notebook, and Python, performing analyses and visualizations to reveal key insights (revenue, product, customer).\n",
      "    *   Developed and deployed machine learning models in Python (Jupyter Notebook) for missing-value imputation and delivered analytical reports on sales trends and customer behavior.\n",
      "    *   Architected and maintained Dockerized data pipelines with Kafka, MySQL, ClickHouse, and Python for API data ingestion, processing, and storage, supporting advanced analytics.\n",
      "*   **Upcoming Internship:**\n",
      "    *   **Role:** Data Analyst Intern at Beloved & Beyond\n",
      "    *   **Probation Period:** February 2025 - May 2025 (This indicates a scheduled future internship.)\n",
      "\n",
      "**4. Technical Skills and Competencies:**\n",
      "The candidate possesses a broad range of technical and soft skills crucial for data-centric roles.\n",
      "\n",
      "*   **Programming Languages:** Python (Pandas, NumPy, Scikit-learn, TensorFlow, PySpark), R, SQL\n",
      "*   **Databases & Querying:** SQL Server, MySQL, PostgreSQL, ClickHouse, MongoDB, Cassandra\n",
      "*   **Machine Learning:**\n",
      "    *   **Algorithms:** Regression, Classification, Clustering, Recommender Systems (Matrix Factorization, KNN), Online Learning (SGD, Passive-Aggressive), Time Series Forecasting\n",
      "    *   **Methodologies:** Data Cleaning & Preprocessing, Feature Engineering & Selection, Model Evaluation & Tuning (Cross-validation, Grid Search), Pattern Recognition & Anomaly Detection\n",
      "*   **Tools & Platforms:** Apache Spark, Airflow, Docker, Kafka, Git, REST API (Postman)\n",
      "*   **Visualization & BI:** Power BI (DAX), Grafana, Excel\n",
      "*   **Statistical Analysis:** Hypothesis Testing, A/B Testing\n",
      "*   **Domain Knowledge:** E-commerce, Finance, Education\n",
      "*   **Soft Skills & Methodologies:** Data-Driven Problem Solving, Business Intelligence & KPI Analysis, Data Storytelling for Stakeholders, Project Planning & Execution, Communication with Technical & Non-Technical Teams, Business Acumen in Decision-Making.\n",
      "*   **Certifications:**\n",
      "    *   Hacker Rank: SQL (Advanced), Python (Basic)\n",
      "    *   English: B1 certification, Fluent in English\n",
      "\n",
      "**5. Key Projects and Accomplishments:**\n",
      "The candidate has undertaken impressive personal projects, all with a projected completion/conducted date of May 2025, which suggests they are current intensive efforts or planned capstone projects.\n",
      "\n",
      "*   **Credit Risk & Customer Segmentation (Conducted in: 05/2025):**\n",
      "    *   **Process:** End-to-end analysis on credit risk data, including cleaning, normalization, missing value handling, and class balancing (SMOTE).\n",
      "    *   **Modeling:** Evaluated 13 ML models, selected the best performer (AUC > 0.85, F1 > 0.8).\n",
      "    *   **Segmentation:** Utilized t-SNE and Davies–Bouldin for customer segmentation (high-risk, loyal, high-potential).\n",
      "    *   **Deployment/Output:** Developed a Power BI dashboard and real-time REST API for insights.\n",
      "    *   **Impact:** Claimed reduction in non-performing loans and boosted campaign effectiveness.\n",
      "*   **Service Usage Behavior Analysis Customer Churn Prediction (Conducted in: 05/2025):**\n",
      "    *   **Process:** Conducted EDA (Jupyter Notebook, Python), visualized churn patterns and segments (Power BI).\n",
      "    *   **Modeling:** Built an XGBoost churn prediction model (F1 ≈ 0.84, AUC ≈ 0.99).\n",
      "    *   **Deployment/Integration:** Integrated with a REST API, tested in Postman.\n",
      "    *   **Impact:** Identified high-risk groups, proposed retention strategies, flagged over 80% of potential churn cases.\n",
      "*   **Product Recommendation & User Behavior Analysis (Conducted in: 05/2025):**\n",
      "    *   **Process:** Data cleaning, normalization, imputation, outlier handling; computed key metrics (AOV, purchase frequency, review scores).\n",
      "    *   **Modeling/Segmentation:** User segmentation with KMeans; built a hybrid recommendation system (ALS-based matrix factorization + KNN).\n",
      "    *   **Visualization:** Interactive Power BI dashboard.\n",
      "    *   **Impact:** Achieved a 15% increase in recommendation accuracy, enhanced coverage and diversity, enabling more effective marketing campaigns and operational decisions.\n",
      "*   **Honors & Awards:**\n",
      "    *   **MyInsight - MDS Datathon Challenge 2025 (Competition Period: 05/2025):** Led and supported a team to the semi-final round, placing in the TOP 20 out of hundreds of participants.\n",
      "\n",
      "**6. Overall Professional Profile:**\n",
      "Truong Nguyen Thanh Tu presents as a highly ambitious and self-driven Applied Mathematics student with a strong passion for data science. Despite being early in their academic journey (expected graduation 2027), they have proactively acquired a wide array of technical skills across programming, databases, machine learning, and MLOps tools.\n",
      "\n",
      "Their objective clearly states a desire to become a data specialist who drives business value through strategic insights. The candidate demonstrates a solid foundation in core data science concepts, evidenced by detailed personal projects covering diverse areas like credit risk, churn prediction, and recommender systems. These projects showcase end-to-end capabilities, from data cleaning and modeling to visualization and API deployment, and emphasize business impact.\n",
      "\n",
      "The inclusion of an upcoming Data Analyst Intern role and a recent Datathon achievement further highlights their dedication to gaining practical experience and proving their abilities in a competitive environment. They possess both technical depth and valuable soft skills like data storytelling, communication, and business acumen.\n",
      "\n",
      "## Conclusion:\n",
      "\n",
      "Truong Nguyen Thanh Tu is a **highly promising and proactive junior data professional**. Their resume showcases an exceptional commitment to learning and applying complex data science techniques well beyond typical undergraduate expectations.\n",
      "\n",
      "**Strengths:**\n",
      "*   **Strong Foundation:** Excellent theoretical background from Applied Mathematics, combined with practical hands-on experience in diverse data science projects.\n",
      "*   **Broad Skillset:** Demonstrates proficiency in a comprehensive suite of tools and technologies relevant to modern data science and engineering roles, including big data tools (Spark, Kafka), MLOps (Docker, Airflow), and advanced ML techniques.\n",
      "*   **Project-Oriented Learning:** The personal projects are a significant highlight, demonstrating the ability to independently conceive, execute, and deliver impactful data solutions, focusing on business value. The projects cover crucial aspects like data cleaning, various ML models, deployment (API), and visualization.\n",
      "*   **Business Acumen:** Explicitly mentions skills in KPI analysis, data storytelling, communication, and business acumen, indicating a clear understanding of how data translates into business decisions.\n",
      "*   **Proactive & Ambitious:** The future-dated internship and datathon achievement, alongside the self-taught skills and detailed projects, underscore a highly motivated individual eager to accelerate their career in data.\n",
      "\n",
      "**Areas for Clarification/Potential Improvement (for the candidate):**\n",
      "*   **Dates Consistency:** The most significant observation is that nearly all significant \"accomplishments\" (personal projects, datathon, and even the listed internship) are dated \"05/2025\" or \"02/2025-05/2025\". If this resume is being reviewed *before* these dates, it creates ambiguity. It would be clearer if these were explicitly marked as \"Planned,\" \"Ongoing,\" or \"Expected Completion\" if they haven't happened yet. If they *have* happened, the dates should reflect the actual completion. This precision is important for a data professional.\n",
      "*   **Context for \"Professional Experience\" Bullet Points:** The first three bullet points under \"PROFESSIONAL EXPERIENCE\" are not tied to a specific company or role (other than the upcoming internship). It would strengthen the resume to clarify the context of these achievements (e.g., \"From academic capstone projects,\" \"Volunteer work,\" \"Self-initiated case studies\").\n",
      "\n",
      "In summary, Truong Nguyen Thanh Tu is an impressive candidate for entry-level Data Scientist or Data Analyst roles, particularly those with a strong emphasis on machine learning and practical problem-solving. Their drive, technical breadth, and project experience position them as a valuable asset for organizations looking for emerging talent who can quickly contribute to data-driven initiatives. Clarifying the timelines of their listed accomplishments would make their already strong profile even more compelling.\n"
     ]
    }
   ],
   "source": [
    "# Execute analysis\n",
    "print(\"=== RESUME SUMMARY ===\")\n",
    "summary_prompt = resume_summary()\n",
    "summary_result = gemini_analyze_simple(gemini_api_key=gemini_api_key, resume_text=text, analyze_prompt=summary_prompt)\n",
    "print(summary_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1db1118-a038-450a-bc32-cdd19f0ae667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "=== RESUME STRENGTHS ===\n",
      "This resume presents a highly promising candidate with a strong foundation and impressive practical experience for an early-career professional in data science. Here's a detailed analysis of its strengths:\n",
      "\n",
      "---\n",
      "\n",
      "### Detailed Analysis of Strengths:\n",
      "\n",
      "**1. Technical Skills and Expertise:**\n",
      "*   **Comprehensive Programming:** Proficiency in Python (with key libraries like Pandas, NumPy, Scikit-learn, TensorFlow, PySpark) and R covers a wide spectrum of data manipulation, analysis, machine learning, and big data processing. SQL is fundamental and covered thoroughly.\n",
      "*   **Diverse Databases & Querying:** Demonstrates experience with a remarkable variety of database systems (SQL Server, MySQL, PostgreSQL, ClickHouse, MongoDB, Cassandra). This breadth (relational, NoSQL, analytical column-store) is exceptional for a student, indicating adaptability and strong data handling capabilities.\n",
      "*   **Machine Learning Breadth:** Covers core ML areas like Regression, Classification, Clustering, and Recommender Systems. The inclusion of Online Learning (SGD, Passive-Aggressive) and Time Series Forecasting shows a deeper understanding of practical and advanced ML applications.\n",
      "*   **Advanced Tools & Platforms:**\n",
      "    *   **Big Data:** Apache Spark and PySpark expertise is a significant advantage for handling large datasets.\n",
      "    *   **Data Orchestration & Streaming:** Airflow and Kafka are highly sought-after skills for building robust, scalable data pipelines and real-time data processing.\n",
      "    *   **Containerization:** Docker proficiency is crucial for reproducible environments and deployment.\n",
      "    *   **Version Control & API Interaction:** Git and REST API (Postman) are essential for collaborative development and integrating solutions.\n",
      "*   **Visualization & BI:** Strong command of Power BI (including DAX), Grafana, and Excel ensures effective data communication and dashboard creation.\n",
      "*   **Data Science Methodologies:** Clearly lists crucial steps like Data Cleaning & Preprocessing, Feature Engineering & Selection, Model Evaluation & Tuning (Cross-validation, Grid Search), Statistical Analysis (Hypothesis Testing, A/B Testing), and Pattern Recognition & Anomaly Detection. This shows a holistic understanding of the data science lifecycle.\n",
      "*   **HackerRank Certifications:** SQL (Advanced) provides external validation of core data manipulation skills, which is highly valuable. Python (Basic) is a good starting point, though the libraries listed imply a higher practical proficiency.\n",
      "\n",
      "**2. Professional Experience Highlights:**\n",
      "*   **MyInsight - MDS Datathon Challenge 2025:**\n",
      "    *   Demonstrates strong competitive drive and performance (\"TOP 20 out of hundreds\").\n",
      "    *   Highlights leadership and teamwork (\"Led and supported a team\").\n",
      "    *   Showcases ability to perform under pressure and solve complex problems within a time limit.\n",
      "*   **Data Analyst Intern (Beloved & Beyond):** While listed as a \"Probation Period\" in 02/2025-05/2025 (implying a future/very recent start), it signifies securing a formal internship, which is a positive step.\n",
      "*   **Practical Data Handling & ML Application (likely from projects or self-study but presented as general experience):**\n",
      "    *   \"Managed and cleansed multi-million-row datasets using Excel, Jupyter Notebook, and Python, then performed analyses and visualizations to reveal key revenue, product, and customer insights.\" This demonstrates ability to handle large-scale data and extract business value.\n",
      "    *   \"Developed and deployed machine learning models in Python (Jupyter Notebook) for missing-value imputation and delivered analytical reports on sales trends and customer behavior.\" Shows direct application of ML for practical data quality and business reporting.\n",
      "    *   \"Architected and maintained Dockerized data pipelines with Kafka, MySQL, ClickHouse, and Python to ingest, process, and store API data for advanced analytics.\" This is an *outstanding* highlight. It indicates significant data engineering capabilities, including real-time data processing (Kafka), scalable architecture (Docker), and diverse database integration, which is rare for an early-career individual.\n",
      "\n",
      "**3. Educational Qualifications:**\n",
      "*   **Applied Mathematics Major:** A strong academic foundation in Applied Mathematics from Ton Duc Thang University (2023-2027) provides a robust theoretical background in arithmetic, matrix theory, and statistical concepts, which are fundamental to advanced data science and machine learning.\n",
      "*   **English Fluency:** English B1 certification and stated fluency are critical for communication in global teams and accessing a wider range of resources.\n",
      "\n",
      "**4. Project Achievements:**\n",
      "*   **End-to-End Data Science Lifecycle:** All projects demonstrate the ability to conduct analysis from data cleaning and preprocessing through model building, evaluation, deployment (API, Docker), and visualization.\n",
      "*   **Advanced ML Techniques Applied:**\n",
      "    *   *Credit Risk & Customer Segmentation:* Extensive model evaluation (13 models), robust metrics (AUC > 0.85, F1 > 0.8), advanced segmentation techniques (t-SNE, Davies–Bouldin), and deployment via Power BI dashboard and REST API.\n",
      "    *   *Service Usage Behavior Analysis Customer Churn Prediction:* Strong model selection (XGBoost with high F1 and AUC), API integration, and clear business impact (flagging over 80% of potential churn cases).\n",
      "    *   *Product Recommendation & User Behavior Analysis:* Sophisticated hybrid recommendation system (ALS-based matrix factorization + KNN) and quantifiable impact (\"15% increase in recommendation accuracy\").\n",
      "*   **Business Impact Focus:** Each project clearly articulates the business value derived (reducing non-performing loans, boosting campaign effectiveness, flagging churn, increasing recommendation accuracy, enhancing marketing). This shows a strong understanding of how data science translates into business outcomes.\n",
      "*   **Deployment and Integration:** Repeated demonstration of building and integrating solutions via REST APIs and Docker is a major plus, indicating readiness for production environments.\n",
      "*   **GitHub Portfolio:** Providing a link to GitHub allows for verification of code quality, project structure, and practical skills.\n",
      "\n",
      "**5. Industry Knowledge:**\n",
      "*   **Directly Stated Domain Knowledge:** Explicitly lists E-commerce, Finance, and Education, which are highly relevant industries for data science roles.\n",
      "*   **Projects Reinforce Domains:** The Credit Risk project aligns with Finance, and Product Recommendation and Customer Churn align strongly with E-commerce/Retail.\n",
      "\n",
      "**6. Soft Skills Demonstrated:**\n",
      "*   **Proactivity & Self-Learning:** \"Proactively learning and applying data-analysis tools\" and the breadth of tools/techniques acquired demonstrate strong initiative.\n",
      "*   **Data-Driven Problem Solving:** Explicitly stated and evident in every project description, focusing on turning data into solutions.\n",
      "*   **Teamwork & Leadership:** \"Led and supported a team\" in a competitive environment.\n",
      "*   **Communication Skills:** \"Data Storytelling for Stakeholders,\" \"Communication with Technical & Non-Technical Teams,\" and delivering \"analytical reports\" highlight strong ability to convey complex insights.\n",
      "*   **Business Acumen:** \"Business Acumen in Decision-Making\" and the consistent focus on quantifiable business impacts in projects show a valuable understanding of commercial objectives.\n",
      "*   **Analytical Thinking:** Rooted in the Applied Mathematics background and demonstrated through statistical analysis, pattern recognition, and detailed model evaluation.\n",
      "*   **Goal-Oriented:** A clear, ambitious two-year aspiration to become a \"data specialist who drives business value.\"\n",
      "\n",
      "---\n",
      "\n",
      "### Main Competitive Advantages of this Candidate:\n",
      "\n",
      "1.  **Exceptional Practical Data Engineering Skills:** The ability to \"Architect and maintain Dockerized data pipelines with Kafka, MySQL, ClickHouse, and Python\" is incredibly valuable and typically not seen in early-career data scientists who often focus solely on modeling. This skill set positions them as a full-stack data professional capable of building scalable infrastructure.\n",
      "2.  **Demonstrated End-to-End Project Ownership with Business Impact:** The projects are not just theoretical exercises; they cover the entire data science lifecycle from cleaning to deployment and consistently highlight tangible business outcomes with impressive metrics (e.g., AUC > 0.85, F1 > 0.8, 15% accuracy increase, flagging 80% churn).\n",
      "3.  **Strong Blend of Theoretical Foundation and Practical Application:** The Applied Mathematics background provides robust statistical and mathematical understanding, perfectly complemented by hands-on experience with a wide array of industry-standard tools and technologies.\n",
      "4.  **Proactive and Rapid Learner:** The sheer volume and diversity of technologies and techniques mastered in a relatively short academic period (2023-2027 implies current student) demonstrate a high capacity for learning and applying new knowledge quickly.\n",
      "5.  **Effective Communication and Business Acumen:** The candidate clearly understands the importance of translating technical insights into actionable business strategies and can communicate effectively with diverse audiences, which is a critical skill for any data role.\n",
      "\n",
      "In conclusion, Truong Nguyen Thanh Tu is a highly motivated and technically proficient candidate with a rare combination of strong foundational knowledge, advanced practical data engineering and machine learning skills, and a clear focus on delivering business value. Their project portfolio and self-driven learning are particularly impressive for someone still in university.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"=== RESUME STRENGTHS ===\")\n",
    "strength_prompt = resume_strength()\n",
    "strength_result = gemini_analyze_simple(gemini_api_key=gemini_api_key, resume_text=text, analyze_prompt=strength_prompt)\n",
    "print(strength_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "442fccde-c99a-454e-95b4-38c2b8ac46ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "=== RESUME WEAKNESSES ===\n",
      "This resume shows a strong understanding of data science concepts and tools, with impressive project descriptions. However, there are critical weaknesses that undermine its credibility and effectiveness.\n",
      "\n",
      "Here's a detailed analysis of the weaknesses and suggestions for improvement:\n",
      "\n",
      "---\n",
      "\n",
      "### **Detailed Analysis of Weaknesses and Suggestions for Improvement**\n",
      "\n",
      "**1. Critical Credibility Issue: Future-Dated Experience and Projects**\n",
      "\n",
      "*   **Weakness:** This is the most significant and damaging issue. All professional experience, honors, and personal projects are dated for **05/2025** or **02/2025-05/2025**. This implies that none of these accomplishments have actually happened yet, or that the dates are entirely incorrect. Recruiters will immediately flag this as a major red flag, potentially dismissing the resume entirely.\n",
      "*   **Specific Examples:**\n",
      "    *   `Beloved & Beyond ---- Role: Data Analyst Intern ---- Probation Period: 02/2025-05/2025`\n",
      "    *   `MyInsight - MDS Datathon Challenge 2025 ---- Competition Period: 05/2025`\n",
      "    *   `Credit Risk & Customer Segmentation ---- Conducted in: 05/2025` (and all other projects)\n",
      "*   **Impact:** Destroys credibility. Makes the candidate appear as if they are listing hypothetical future work rather than actual achievements.\n",
      "*   **Recommendation:**\n",
      "    *   **ABSOLUTELY ESSENTIAL:** Correct all dates to reflect the actual completion or ongoing periods.\n",
      "    *   If these projects/experiences are truly planned for the future (e.g., a secured internship, a future competition), they should be explicitly labeled as \"Expected Internship\" or \"Upcoming Competition\" with *expected dates*. However, it's generally not advisable to list experiences that haven't occurred unless they are highly prestigious and *secured*.\n",
      "    *   If the projects are academic simulations or part of a course, state that clearly (e.g., \"Academic Project,\" \"Capstone Project\").\n",
      "\n",
      "**2. Summary/Objective Section**\n",
      "\n",
      "*   **Weakness:** The current \"OBJECTIVE\" reads more like a personal career aspiration statement (\"Applied Mathematics student,\" \"Proactively learning,\" \"aim to deepen my expertise,\" \"Within two years, I aspire to become...\") rather than a professional summary of qualifications and value proposition for an employer. It focuses on what the candidate *wants* to do, not what they *can do now*.\n",
      "*   **Recommendation:**\n",
      "    *   Rename \"OBJECTIVE\" to \"PROFESSIONAL SUMMARY\" or \"SUMMARY.\"\n",
      "    *   Rewrite to highlight your key skills, relevant experience (even if academic), and what you bring to a data-focused role *today*.\n",
      "    *   **Example Revision:** \"Applied Mathematics student with a strong foundation in statistical analysis and machine learning, adept at leveraging Python (Pandas, NumPy, Scikit-learn, TensorFlow) and SQL for data analysis, modeling, and insight generation. Proven ability to clean, transform, and visualize complex datasets, develop predictive models, and communicate data-driven recommendations to drive business value. Eager to apply analytical expertise in a dynamic data specialist role.\"\n",
      "\n",
      "**3. Experience Gaps & Clarity**\n",
      "\n",
      "*   **Weakness:** Aside from the future-dated \"Probation Period,\" there is no other professional experience listed. For a student, academic projects are crucial, but any actual internship or part-time data-related work experience would significantly strengthen the resume.\n",
      "*   **Weakness:** The \"Probation Period\" title is unusual for an internship. \"Data Analyst Intern\" is standard. If it's a secured internship, clarify that it's \"Incoming\" or \"Expected.\" If it's not secured, remove it.\n",
      "*   **Recommendation:**\n",
      "    *   If you have *any* past internships, volunteer data roles, or relevant part-time jobs (even if not explicitly \"Data Analyst\"), include them.\n",
      "    *   Clarify the nature of the \"Beloved & Beyond\" entry. If it's an internship you've secured but hasn't started, write \"Incoming Data Analyst Intern (Expected: Feb 2025 - May 2025)\". If it's a potential opportunity, remove it.\n",
      "\n",
      "**4. Skills Section - Detail and Alignment**\n",
      "\n",
      "*   **Weakness:** The \"Resume Content\" skill list is very comprehensive and impressive, but it's separate from the \"STRENGTHS AND EXPERTISE\" section on the resume. This can be confusing.\n",
      "*   **Weakness:** \"Python (Basic)\" in Certifications contradicts the advanced Python libraries listed (Pandas, NumPy, Scikit-learn, TensorFlow, PySpark). If you are proficient enough to use these libraries in projects and build models, your Python skill level is likely beyond \"Basic.\" This creates doubt.\n",
      "*   **Recommendation:**\n",
      "    *   Consolidate all technical skills into a single, well-organized \"Technical Skills\" or \"Skills\" section. You can use categories like \"Programming,\" \"Databases,\" \"ML Libraries,\" \"Tools,\" etc., as you currently have.\n",
      "    *   Re-evaluate your Python proficiency. If you've used those advanced libraries, consider changing \"Python (Basic)\" to \"Python (Intermediate)\" or simply remove the \"Basic\" qualifier if your projects demonstrate strong capability. It's better to let your project work speak for your proficiency.\n",
      "    *   Consider adding specific data structures, algorithms, or statistical methods you're familiar with under \"Machine Learning\" or \"Statistical Analysis.\"\n",
      "\n",
      "**5. Education Section**\n",
      "\n",
      "*   **Weakness:** Missing GPA. For an Applied Mathematics student, a strong GPA (especially in relevant courses) is a significant asset.\n",
      "*   **Weakness:** No mention of relevant coursework. This is crucial for a student to demonstrate foundational knowledge in areas like statistics, linear algebra, calculus, discrete mathematics, optimization, and programming.\n",
      "*   **Recommendation:**\n",
      "    *   Include your GPA if it is strong (e.g., 3.5/4.0 or higher).\n",
      "    *   List 3-5 relevant courses (e.g., \"Relevant Coursework: Linear Algebra, Probability & Statistics, Numerical Methods, Machine Learning Algorithms, Python for Data Science\").\n",
      "\n",
      "**6. Project Descriptions - Already Strong, but Potential for More**\n",
      "\n",
      "*   **Weakness:** (Already covered) The \"Conducted in: 05/2025\" is the only flaw here.\n",
      "*   **Weakness:** While excellent, some descriptions could subtly incorporate more of your \"Business Intelligence & KPI Analysis,\" \"Data Storytelling,\" and \"Communication\" skills explicitly within the bullet points.\n",
      "*   **Recommendation:**\n",
      "    *   **Fix dates.**\n",
      "    *   Incorporate more soft skills naturally. For example, instead of just \"Developed a Power BI dashboard...\", you could say \"Developed a Power BI dashboard to *visualize key insights and facilitate data-driven decision-making for* credit and marketing teams, reducing non-performing loans...\" or \"Presented findings through engaging data stories in Power BI to stakeholders, enabling...\"\n",
      "\n",
      "**7. Formatting and Presentation**\n",
      "\n",
      "*   **Weakness:** The current layout has distinct sections for \"Resume Content\" and then the actual resume, which is confusing in the prompt. Assuming the entire text provided *is* the resume:\n",
      "    *   The \"STRENGTHS AND EXPERTISE\" section is okay, but some skills here could be directly tied to actions in projects (e.g., \"Data Cleaning & Preprocessing\" is shown, but explicitly listing it as a \"strength\" then demonstrating it is good).\n",
      "    *   The overall resume flow is a bit choppy with the skills lists at the top.\n",
      "*   **Recommendation:**\n",
      "    *   Ensure all skills are consolidated under one \"Skills\" section (e.g., just above projects or after education).\n",
      "    *   Consider using slightly more visual separation between sections (e.g., thin lines or more whitespace) if the current format is too dense.\n",
      "    *   Maintain consistency in bullet point structure (action verb + what + result/impact). You've done well here.\n",
      "\n",
      "---\n",
      "\n",
      "### **Actionable Steps to Make This Resume Stronger**\n",
      "\n",
      "1.  **Rectify All Dates IMMEDIATELY:**\n",
      "    *   For **\"Beloved & Beyond\"** and **\"MyInsight - MDS Datathon Challenge\"**: If these are *secured* future events, clearly label them (e.g., \"Incoming Data Analyst Intern,\" \"Expected Competition Participation\"). If they are not secured or purely speculative, **REMOVE THEM** from the resume. Recruiters look for past accomplishments, not future aspirations in these sections.\n",
      "    *   For **\"Personal Projects\"**: Change \"Conducted in: 05/2025\" to the actual completion date (e.g., \"Completed: Jan 2024,\" \"Ongoing\"). This is *critical* for demonstrating you have already done this work.\n",
      "\n",
      "2.  **Rewrite Your Professional Summary:**\n",
      "    *   Change \"OBJECTIVE\" to \"PROFESSIONAL SUMMARY.\"\n",
      "    *   Craft a 3-4 line summary that highlights your current skills, academic background, and the value you can bring to a data role. Focus on accomplishments and expertise, not future goals.\n",
      "\n",
      "3.  **Consolidate and Refine Skills Section:**\n",
      "    *   Combine \"Programming,\" \"Databases,\" \"Machine Learning,\" \"Tools & Platforms,\" \"Visualization & BI\" (from \"Resume Content\") with \"STRENGTHS AND EXPERTISE\" into a single, well-structured \"Technical Skills\" section.\n",
      "    *   Re-evaluate \"Python (Basic)\" in your certifications. If you actively use advanced libraries like TensorFlow and PySpark, your Python level is not \"Basic.\" Update this or remove the qualifier.\n",
      "\n",
      "4.  **Enhance Education Section:**\n",
      "    *   Add your GPA if it's strong (3.5/4.0 or higher).\n",
      "    *   List 3-5 relevant courses from your Applied Mathematics major that demonstrate your foundational knowledge (e.g., Statistics, Linear Algebra, Optimization, Programming for Data Science).\n",
      "\n",
      "5.  **Integrate Soft Skills into Project Descriptions:**\n",
      "    *   While you have a separate list of soft skills, try to naturally weave them into your project bullet points to provide concrete examples. For instance, show \"Data Storytelling\" by describing how your visualizations *enabled stakeholders to make specific decisions*. Show \"Communication\" by mentioning presenting findings to technical/non-technical teams.\n",
      "\n",
      "6.  **Review and Proofread Meticulously:**\n",
      "    *   Check for any typos, grammatical errors, and formatting inconsistencies.\n",
      "    *   Ensure consistent tense (past tense for completed actions).\n",
      "\n",
      "By addressing these points, especially the critical issue of future-dated entries, your resume will transform from a promising but questionable document into a strong, credible representation of your capabilities as an aspiring data specialist.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"=== RESUME WEAKNESSES ===\")\n",
    "weakness_prompt = resume_weakness()\n",
    "weakness_result = gemini_analyze_simple(gemini_api_key=gemini_api_key, resume_text=text, analyze_prompt=weakness_prompt)\n",
    "print(weakness_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8e0abbc6-520b-4dd8-8611-8f56eb605776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "=== JOB TITLE SUGGESTIONS ===\n",
      "This candidate, Truong Nguyen Thanh Tu, presents a highly promising profile for entry-level to junior data roles, especially given the strong technical foundation, proactive learning, and impressive project portfolio for someone still pursuing their undergraduate degree. The \"Applied Mathematics\" background is a significant asset, indicating strong analytical and problem-solving abilities.\n",
      "\n",
      "Here's a detailed analysis of suitable job roles:\n",
      "\n",
      "---\n",
      "\n",
      "### Candidate Profile Summary:\n",
      "\n",
      "**Strengths:**\n",
      "*   **Strong Quantitative Foundation:** Applied Mathematics major provides a solid base in statistics, linear algebra, and problem-solving.\n",
      "*   **Exceptional Technical Breadth & Depth for Junior Level:** Proficient in Python (with key libraries), R, SQL, a wide array of databases (including NoSQL and columnar stores like ClickHouse), and critical big data tools (Spark, Kafka, Docker, Airflow).\n",
      "*   **Robust Machine Learning Skills:** Covers the full ML lifecycle from data prep to model evaluation and deployment, with experience in various algorithms and recommender systems.\n",
      "*   **Practical Project Experience:** Three comprehensive personal projects showcasing end-to-end data science and machine learning capabilities, including API integration and dashboarding.\n",
      "*   **Business Acumen:** Explicitly lists \"Business Acumen,\" \"Data Storytelling,\" and \"Domain Knowledge\" in key areas (E-commerce, Finance, Education).\n",
      "*   **Proactive Learner:** The objective and the range of skills learned demonstrate a high level of self-motivation.\n",
      "*   **Upcoming Internship:** The Data Analyst Intern role, though a probation period, provides initial corporate experience.\n",
      "\n",
      "**Considerations:**\n",
      "*   **Limited Professional Experience:** The only listed professional experience is an upcoming internship. This means the candidate will be primarily competing for intern or junior-level positions.\n",
      "*   **Still a Student:** Expected graduation in 2027 implies current roles would need to be internships, part-time, or full-time roles with a distant start date. This is a crucial factor for recruiters.\n",
      "*   **\"Python (Basic)\" certification:** While the resume clearly demonstrates advanced Python usage through projects (TensorFlow, PySpark), this specific certification might be a minor point of confusion.\n",
      "\n",
      "---\n",
      "\n",
      "### Most Suitable Job Roles\n",
      "\n",
      "#### Primary Job Titles (Perfect Match for Skills & Aspirations)\n",
      "\n",
      "These roles directly leverage the candidate's core strengths in machine learning, mathematics, and data processing.\n",
      "\n",
      "1.  **Junior Data Scientist / Data Scientist Intern:**\n",
      "    *   **Why:** This aligns perfectly with the objective, the \"Data Scientist\" title under the name, the applied mathematics background, and the comprehensive ML projects (Credit Risk, Churn Prediction, Product Recommendation) which cover the full data science lifecycle. Skills like statistical analysis, model evaluation, and feature engineering are core.\n",
      "2.  **Junior Machine Learning Engineer / Machine Learning Engineer Intern:**\n",
      "    *   **Why:** While often requiring more software engineering depth, this candidate's experience with TensorFlow, PySpark, Docker, Kafka, Airflow, and building REST APIs for model deployment (as seen in projects) makes them a strong candidate. This role emphasizes the operationalization of ML models.\n",
      "3.  **Junior Applied Scientist / Applied Scientist Intern:**\n",
      "    *   **Why:** Common in research-heavy tech companies, this role values a strong theoretical (Applied Math) and practical (ML implementation) background. It often involves developing novel algorithms and solutions, which aligns well with the depth of the candidate's projects.\n",
      "\n",
      "#### Secondary Job Titles (Good Fit, Leveraging Specific Strengths)\n",
      "\n",
      "These roles are excellent options, potentially serving as stepping stones or alternative pathways, depending on the company's specific needs and definition of the role.\n",
      "\n",
      "1.  **Junior Data Engineer / Data Engineer Intern:**\n",
      "    *   **Why:** This is a surprisingly strong fit. The experience with \"Architected and maintained Dockerized data pipelines with Kafka, MySQL, ClickHouse, and Python to ingest, process, and store API data\" from the datathon is highly valuable for Data Engineering roles. Skills like Spark, Airflow, and diverse databases are also critical. While the primary interest seems ML, these skills are in high demand and could offer a strong career path.\n",
      "2.  **Junior Data Analyst / Data Analyst Intern:**\n",
      "    *   **Why:** The upcoming \"Data Analyst Intern\" role, strong SQL, Power BI, Excel, data cleaning/preprocessing, and storytelling skills make this a direct fit. While the candidate's ML skills might be \"overqualified\" for some pure DA roles, many companies are looking for analysts with statistical modeling capabilities. This is a solid entry point into the data field.\n",
      "3.  **Business Intelligence (BI) Developer / BI Analyst Intern:**\n",
      "    *   **Why:** Strong Power BI (DAX), Grafana, Excel, SQL, and \"Business Intelligence & KPI Analysis\" align perfectly with BI roles. The ability to connect insights to business value and storytell is crucial here.\n",
      "\n",
      "---\n",
      "\n",
      "### Industries and Company Types to Target\n",
      "\n",
      "Given the candidate's domain knowledge and technical skills, they are well-suited for a variety of sectors:\n",
      "\n",
      "*   **Technology/SaaS Companies:** Any company with significant data operations, especially those building data products or relying heavily on analytics and machine learning. This includes cloud providers, software companies, and AI-first startups.\n",
      "*   **E-commerce & Retail:** Direct alignment with \"Product Recommendation\" and \"Service Usage Behavior Analysis Customer Churn Prediction\" projects, plus listed domain knowledge. These sectors are highly data-driven.\n",
      "*   **Finance & Fintech:** Direct alignment with \"Credit Risk\" project and listed domain knowledge. Companies in banking, lending, investment, and payment processing.\n",
      "*   **Education Technology (EdTech):** Listed domain knowledge. Companies focused on learning platforms, educational tools, and student analytics.\n",
      "*   **Consulting Firms (Data/Analytics Practices):** Firms that offer data science, analytics, or AI consulting services to diverse clients. These environments can provide exposure to various industries.\n",
      "*   **Startups:** Often more flexible with roles, offering opportunities to wear multiple hats and gain diverse experience. They might value the candidate's breadth of skills.\n",
      "*   **Large Enterprises (with dedicated Data Science/ML teams):** Companies in various sectors (telecom, healthcare, logistics) that have established data departments and structured internship programs.\n",
      "\n",
      "---\n",
      "\n",
      "### Required Skills to Highlight in Applications\n",
      "\n",
      "When applying, the candidate should tailor their resume and cover letter to emphasize these skills:\n",
      "\n",
      "*   **Core Technical:**\n",
      "    *   **Python:** Specifically mention Pandas, NumPy, Scikit-learn, and the practical application (data cleaning, feature engineering, model building).\n",
      "    *   **Machine Learning Algorithms:** Regression, Classification, Clustering, Recommender Systems (mention specific methods like ALS, KNN, XGBoost).\n",
      "    *   **SQL:** Emphasize \"Advanced\" proficiency, and ability to query diverse databases (MySQL, PostgreSQL, ClickHouse).\n",
      "    *   **Data Cleaning & Preprocessing:** Crucial for any data role.\n",
      "    *   **Model Evaluation & Tuning:** Cross-validation, Grid Search, and performance metrics (AUC, F1-score).\n",
      "*   **Advanced/Differentiating Technical:**\n",
      "    *   **Apache Spark (PySpark):** For big data processing.\n",
      "    *   **Docker & Kafka:** Demonstrates MLOps/Data Engineering foundational knowledge.\n",
      "    *   **Airflow:** For workflow orchestration.\n",
      "    *   **TensorFlow:** Deep learning framework exposure.\n",
      "    *   **REST API Integration & Postman:** For model deployment and testing.\n",
      "    *   **Power BI (DAX) & Grafana:** For visualization and dashboarding.\n",
      "*   **Analytical & Statistical:**\n",
      "    *   **Statistical Analysis:** Hypothesis Testing, A/B Testing.\n",
      "    *   **Pattern Recognition & Anomaly Detection.**\n",
      "    *   **Data-Driven Problem Solving.**\n",
      "*   **Soft Skills & Business Acumen:**\n",
      "    *   **Data Storytelling for Stakeholders:** Crucial for communicating insights.\n",
      "    *   **Communication with Technical & Non-Technical Teams:** Essential for collaboration.\n",
      "    *   **Business Acumen in Decision-Making:** Connecting data insights to business value.\n",
      "    *   **Project Planning & Execution:** Evident in personal projects.\n",
      "\n",
      "**Quantifiable Achievements:** Always highlight the quantifiable results from projects (e.g., \"AUC > 0.85, F1 > 0.8,\" \"F1 ≈ 0.84, AUC ≈ 0.99,\" \"15% increase in recommendation accuracy,\" \"flagging over 80% of potential churn cases,\" \"TOP 20 best-performing teams\").\n",
      "\n",
      "---\n",
      "\n",
      "### Career Progression Opportunities\n",
      "\n",
      "This candidate has a strong foundation for a rapid career progression in the data domain:\n",
      "\n",
      "*   **Entry-Level (0-2 years):** Data Scientist Intern, Machine Learning Engineer Intern, Data Analyst Intern, Junior Data Scientist, Junior Machine Learning Engineer, Junior Data Engineer.\n",
      "*   **Mid-Level (2-5 years):** Data Scientist, Machine Learning Engineer, Data Engineer, Senior Data Analyst, BI Developer. Specialization in areas like MLOps, A/B Testing, or specific ML domains (NLP, Computer Vision) might occur.\n",
      "*   **Senior/Lead (5+ years):** Senior Data Scientist, Lead Data Scientist, Principal Data Scientist, Machine Learning Lead, Data Architect, Manager of Data Science/ML Engineering.\n",
      "*   **Management/Strategic (8+ years):** Director of Data Science, Head of Analytics, Chief Data Officer, Product Manager (Data/AI focus).\n",
      "\n",
      "The early exposure to tools like Docker, Kafka, and Airflow, combined with a strong ML focus, positions the candidate well for a future in **MLOps** or **Machine Learning Engineering**, which are highly sought-after and well-compensated roles.\n",
      "\n",
      "---\n",
      "\n",
      "### Top 5 Most Suitable Positions for This Candidate\n",
      "\n",
      "Based on a holistic view of skills, projects, and career aspirations:\n",
      "\n",
      "1.  **Junior Data Scientist / Data Scientist Intern:** This is the most direct and ideal fit. The candidate's comprehensive ML projects, strong mathematical background, and listed aspiration perfectly align. It allows them to apply their analytical and modeling skills broadly.\n",
      "\n",
      "2.  **Junior Machine Learning Engineer / Machine Learning Engineer Intern:** The demonstrated ability to build models, integrate them with APIs, and work with MLOps-relevant tools (Docker, Kafka, Airflow) makes this an extremely strong contender. This role would leverage the candidate's practical deployment skills.\n",
      "\n",
      "3.  **Junior Data Engineer / Data Engineer Intern:** Despite not being the explicit primary goal, the practical experience building data pipelines with Docker, Kafka, Spark, and various databases is highly valuable. This is a crucial foundational role in any data-driven organization, and the candidate has surprisingly robust skills in this area.\n",
      "\n",
      "4.  **Junior Applied Scientist / Applied Scientist Intern:** For companies pushing the boundaries of data application, the strong theoretical grounding from Applied Mathematics combined with hands-on ML implementation makes this a very strong fit, especially in R&D or innovation-focused teams.\n",
      "\n",
      "5.  **Junior Data Analyst / Data Analyst Intern:** While perhaps not fully utilizing all of the candidate's advanced ML/DE skills, this is a very strong and accessible entry point. Their robust SQL, visualization (Power BI), statistical analysis, and communication skills would make them an exceptional data analyst, and they could likely transition to more data science-centric roles within the same company.\n",
      "\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"=== JOB TITLE SUGGESTIONS ===\")\n",
    "suggestion_prompt = job_title_suggestion()\n",
    "suggestion_result = gemini_analyze_simple(gemini_api_key=gemini_api_key, resume_text=text, analyze_prompt=suggestion_prompt)\n",
    "print(suggestion_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16075754-4e32-4aed-80d6-9a74f1db653a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
